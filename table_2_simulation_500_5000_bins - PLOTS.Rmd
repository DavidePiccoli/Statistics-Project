---
title: "R Notebook"
output: html_notebook
---

```{r}
# Install the package if it's not already installed
if (!require(KScorrect)) {
  install.packages("KScorrect")
}
```

```{r}
# Load the package
library(KScorrect)

```



In this notebook we are using the four_categories and ten_categories function as in the paper, for both KS and Chi-square.

```{r}
four_categories <- function(x) {
  y_i <- x
  
  Y_C_four_categories <- ifelse(y_i <= 2, 1,
                 ifelse(y_i > 2 & y_i <= 3, 2,
                        ifelse(y_i > 3 & y_i <= 4, 3, 4)))
  
  return(Y_C_four_categories)
}

ten_categories <- function(x) {
  y_i <- x
  
  Y_C_ten_categories <- ifelse(y_i <= 1, 1,
                 ifelse(y_i > 1 & y_i <= 2, 2,
                  ifelse(y_i > 2 & y_i <= 2.5, 3,
                  ifelse(y_i > 2.5 & y_i <= 3, 4,
                  ifelse(y_i > 3 & y_i <= 3.5, 5,
                  ifelse(y_i > 3.5 & y_i <= 4, 6,
                  ifelse(y_i > 4 & y_i <= 4.5, 7,
                  ifelse(y_i > 4.5 & y_i <= 5, 8,
                  ifelse(y_i > 5 & y_i <= 5.5, 9, 10)))))))))
  
  return(Y_C_ten_categories)
}
```


```{r}
# Define the discrete KS test function
discrete_ks_test <- function(x, y, bins) {
  # binning
  if (bins == 4) {
    x_bin <- four_categories(x)
    y_bin <- four_categories(y)
  } else if (bins == 10) {
    x_bin <- ten_categories(x)
    y_bin <- ten_categories(y)
  }
  
  ks_stat <- ks.test(x_bin, y_bin)
  
  return(ks_stat)
}

# Function to perform the chi-square test
chi_square_test <- function(x, y, bins) {
  # Define the number of bins
  num_bins <- bins   # bins useless here

  # binning
  if (bins == 4) {
    x_bin <- four_categories(x)
    y_bin <- four_categories(y)
  } else if (bins == 10) {
    x_bin <- ten_categories(x)
    y_bin <- ten_categories(y)
  }
  
  # Create the contingency table
  table <- table(x_bin, y_bin)
    
  # Add a small constant to avoid division by zero
  table <- table + 1e-5
  
  # Perform chi-square test
  chi_sq_result <- chisq.test(table)
  
  # Return chi-square statistic
  return(chi_sq_result)
}


# Function to run Monte Carlo simulations
run_simulation <- function(n, dist_shape, bins) {
  # Initialize counters for null hypothesis rejections
  count_ks_reject <- 0
  count_chi_sq_reject <- 0
  
  # Run the simulations
  for (i in 1:1000) {
    x_i1 <- 3*runif(n, 0, 1) + 1
    x_i2 <- 2*runif(n, 0, 1) - 1
    e_i <- qnorm(runif(n, 0, 1))
    
    # Generate data according to specified distribution shape
    if (dist_shape == "right skewed") {
      # Set the beta coefficients
      beta1 <- 0.80
      beta2 <- 1.25
      sigma <- 1
      beta1_2 <- 0.75
      beta2_2 <- 1.25
      sigma_2 <- 1
      
      x <- beta1 * x_i1 + beta2 * x_i2 + sigma * e_i
      
      x_i1 <- 3*runif(n, 0, 1) + 1
      x_i2 <- 2*runif(n, 0, 1) - 1
      e_i <- qnorm(runif(n, 0, 1))
      y <- beta1_2 * x_i1 + beta2_2 * x_i2 + sigma_2 * e_i
    } else if (dist_shape == "left skewed") {
      # Set the beta coefficients
      beta1 <- 1.70
      beta2 <- 1.25
      sigma <- 1
      beta1_2 <- 1.75
      beta2_2 <- 1.25
      sigma_2 <- 1
      
      x <- beta1 * x_i1 + beta2 * x_i2 + sigma * e_i
      
      x_i1 <- 3*runif(n, 0, 1) + 1
      x_i2 <- 2*runif(n, 0, 1) - 1
      e_i <- qnorm(runif(n, 0, 1))
      y <- beta1_2 * x_i1 + beta2_2 * x_i2 + sigma_2 * e_i
    } else if (dist_shape == "bimodal") {
      # Set the beta coefficients
      beta1 <- 1
      beta2 <- 1
      sigma <- 3.5
      beta1_2 <- 1
      beta2_2 <- 1
      sigma_2 <- 4
      
      x <- beta1 * x_i1 + beta2 * x_i2 + sigma * e_i
      
      x_i1 <- 3*runif(n, 0, 1) + 1
      x_i2 <- 2*runif(n, 0, 1) - 1
      e_i <- qnorm(runif(n, 0, 1))
      y <- beta1_2 * x_i1 + beta2_2 * x_i2 + sigma_2 * e_i
    } else if (dist_shape == "uniform") {
      # Set the beta coefficients
      beta1 <- 1
      beta2 <- 1.5
      sigma <- 4
      beta1_2 <- 1
      beta2_2 <- 1
      sigma_2 <- 4
      
      x <- beta1 * x_i1 + beta2 * x_i2 + sigma * e_i
      
      x_i1 <- 3*runif(n, 0, 1) + 1
      x_i2 <- 2*runif(n, 0, 1) - 1
      e_i <- qnorm(runif(n, 0, 1))
      y <- beta1_2 * x_i1 + beta2_2 * x_i2 + sigma_2 * e_i
    }
      
    # Perform tests
    ks_stat <- discrete_ks_test(x, y, bins)
    chi_sq_stat <- chi_square_test(x, y, bins)
    
    # p value
    chi_sq_p_value <- chi_sq_stat$p.value
    ks_p_value <- ks_stat$p.value
    #print(ks_p_value)
    
    # Check if null hypothesis is rejected
    if (ks_p_value < critical_value_ks) {
      count_ks_reject <- count_ks_reject + 1
    }
    if (chi_sq_p_value < critical_value_chi_sq) {
      count_chi_sq_reject <- count_chi_sq_reject + 1
    }
  }
  
  return(c(count_ks_reject / 1000, count_chi_sq_reject / 1000))
}
```

```{r}
n <- 5000
# Set the beta coefficients
# right-skewed
beta1 <- 0.80
beta2 <- 1.25
sigma <- 1
beta1_2 <- 0.75
beta2_2 <- 1.25
sigma_2 <- 1

x <- beta1 * x_i1 + beta2 * x_i2 + sigma * e_i

x_i1 <- 3*runif(n, 0, 1) + 1
x_i2 <- 2*runif(n, 0, 1) - 1
e_i <- qnorm(runif(n, 0, 1))
y <- beta1_2 * x_i1 + beta2_2 * x_i2 + sigma_2 * e_i


bins = 4
# binning
  if (bins == 4) {
    x_bin <- four_categories(x)
    y_bin <- four_categories(y)
  } else if (bins == 10) {
    x_bin <- ten_categories(x)
    y_bin <- ten_categories(y)
  }

# Create the contingency table
table <- table(x_bin, y_bin)

# Add a small constant to avoid division by zero
table <- table + 1e-5

# Perform test
ks_stat <- discrete_ks_test(x, y, bins)
chi_sq_stat <- chi_square_test(x, y, bins)
# p value
chi_sq_p_value <- chi_sq_stat$p.value
ks_p_value <- ks_stat$p.value

print(table)
# Return chi-square statistic
print(chi_sq_p_value)
print(ks_p_value)
```
```{r}
# Calculate empirical cumulative distribution function
p = ecdf(x_bin)

# Plot empirical cumulative distribution function
plot(p, lty=2, main='Different distribution by design (uniform)', xlim=c(1, bins+1))

# add another distribuition
p_2 = ecdf(y_bin)
lines(p_2, lty = 1, col='red')

# Add a legend
legend("bottomright", legend = c("Distribution 1", "Distribution 2"), lty = c(2, 1), col = c("black", "red"))

```
```{r}
n <- 5000
# Set the beta coefficients
# right-skewed
beta1 <- 0.80
beta2 <- 1.25
sigma <- 1
beta1_2 <- 0.75
beta2_2 <- 1.25
sigma_2 <- 1

x <- beta1 * x_i1 + beta2 * x_i2 + sigma * e_i

x_i1 <- 3*runif(n, 0, 1) + 1
x_i2 <- 2*runif(n, 0, 1) - 1
e_i <- qnorm(runif(n, 0, 1))
y <- beta1_2 * x_i1 + beta2_2 * x_i2 + sigma_2 * e_i


bins = 10
# binning
  if (bins == 4) {
    x_bin <- four_categories(x)
    y_bin <- four_categories(y)
  } else if (bins == 10) {
    x_bin <- ten_categories(x)
    y_bin <- ten_categories(y)
  }

# Create the contingency table
table <- table(x_bin, y_bin)

# Add a small constant to avoid division by zero
table <- table + 1e-5

# Perform test
ks_stat <- discrete_ks_test(x, y, bins)
chi_sq_stat <- chi_square_test(x, y, bins)
# p value
chi_sq_p_value <- chi_sq_stat$p.value
ks_p_value <- ks_stat$p.value

print(table)
# Return chi-square statistic
print(chi_sq_p_value)
print(ks_p_value)
```
```{r}
# Calculate empirical cumulative distribution function
p = ecdf(x_bin)

# Plot empirical cumulative distribution function
plot(p, lty=2, main='Different distribution by design (right skewed)', xlim=c(1, bins+1))

# add another distribuition
p_2 = ecdf(y_bin)
lines(p_2, lty = 1, col='red')

# Add a legend
legend("bottomright", legend = c("Distribution 1", "Distribution 2"), lty = c(2, 1), col = c("black", "red"))

```